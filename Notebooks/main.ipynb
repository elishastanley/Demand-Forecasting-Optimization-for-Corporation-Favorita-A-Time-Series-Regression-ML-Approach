{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Demand Forecasting Optimization for Corporation Favorita A Time Series Regression ML Approach**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "1. [Business Understanding](#business-understanding)\n",
    "2. [Data collection](#Data-collection)\n",
    "3. [Data Cleaning and Preparation](#Data-Cleaning-and-Preparation)\n",
    "4. [Hypotheses](#hypotheses)\n",
    "5. [Analytical Questions](#analytical-questions)\n",
    "6. [Data Sources](#data-sources)\n",
    "7. [Process Overview](#process-overview)\n",
    "\n",
    "## **Business Understanding**\n",
    "\n",
    "Corporation Favorita, a large grocery retailer based in Ecuador, aims to optimize its inventory management to ensure the right quantity of products is always in stock across its various locations. Effective inventory management is critical for maintaining high levels of customer satisfaction and minimizing costs associated with overstocking or stockouts.\n",
    "\n",
    "To achieve this goal, we will build machine learning models to forecast the demand for products at different Favorita stores. Accurate demand forecasting will allow Corporation Favorita to make informed decisions regarding stock levels, promotions, and supply chain logistics.\n",
    "\n",
    "#### Objective:\n",
    "1. **Develop Predictive Models**: Create models to forecast daily unit sales for thousands of products across multiple stores.\n",
    "2. **Understand Influencing Factors**: Analyze the impact of various factors on sales, including promotions, holidays, oil prices, store characteristics, and external events such as earthquakes.\n",
    "3. **Optimize Inventory Management**: Use the models to inform inventory decisions, ensuring that the right products are available at the right stores at the right time.\n",
    "\n",
    "#### Hypothesis:\n",
    "1. Null Hypothesis (H0): Promotions do not have a significant impact on sales.\n",
    "   Alternative Hypothesis (H1): Promotions have a significant impact on sales.\n",
    "2. Null Hypothesis (H0): Oil prices do not significantly impact sales.\n",
    "   Alternative Hypothesis (H1): Oil prices significantly impact sales.\n",
    "\n",
    "#### Key Analytical Questions:\n",
    "1. **Data Completeness**: Is the training dataset complete with all required dates?\n",
    "2. **Sales Extremes**: Which dates have the lowest and highest sales for each year (excluding days when stores were closed)?\n",
    "3. **Monthly Sales Trends**: Compare sales across months and years to identify the highest sales month and year.\n",
    "4. **Earthquake Impact**: Did the earthquake in April 2016 impact sales?\n",
    "5. **Store Performance**: Are certain stores or groups of stores (cluster, city, state, type) selling more products?\n",
    "6. **Promotions, Oil Prices, and Holidays**: How are sales affected by promotions, oil prices, and holidays?\n",
    "7. **Date Features Analysis**: What insights can be derived from date-related features?\n",
    "8. **Promotion Impact**: Which product families and stores were most affected by promotions?\n",
    "9. **Error Metrics**: What is the difference between RMSLE, RMSE, and MSE? Why might MAE be greater than these metrics?\n",
    "10. **Wage Payment Influence**: Does the bi-monthly payment of public sector wages influence store sales?\n",
    "\n",
    "\n",
    "#### Data Sources\n",
    "- **train.csv**: Time series data of store, product information, promotions, and sales.\n",
    "- **test.csv**: Features similar to the training data for the 15 days following the last date in the training data.\n",
    "- **transaction.csv**: Daily transactions per store.\n",
    "- **stores.csv**: Metadata about stores including location and type.\n",
    "- **oil.csv**: Daily oil prices.\n",
    "- **holidays_events.csv**: Information about holidays and events, including special designations like transferred, bridge, and work days.\n",
    "- **sample_submission.csv**: A sample submission file for formatting predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Importing Necessary packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "from dotenv import dotenv_values\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import product\n",
    "from scipy import stats\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Collection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading environment variables from .env file\n",
    "environment_variables = dotenv_values('.env')\n",
    "\n",
    "# Getting the values for the credentials set in the .env file\n",
    "server = environment_variables.get(\"SERVER\")\n",
    "database = environment_variables.get(\"DATABASE\")\n",
    "username = environment_variables.get(\"USERNAME\")\n",
    "password = environment_variables.get(\"PASSWORD\")\n",
    "\n",
    "# Creating a connection string\n",
    "connection_string = f\"DRIVER={{SQL Server}}; \\\n",
    "                    SERVER={server}; \\\n",
    "                    DATABASE={database}; \\\n",
    "                    UID={username}; \\\n",
    "                    PWD={password};\"\n",
    "\n",
    "# Connecting to the server\n",
    "connection = pyodbc.connect(connection_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data from the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>dcoilwtico</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>93.139999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>92.970001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>93.120003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>93.199997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  dcoilwtico\n",
       "0  2013-01-01         NaN\n",
       "1  2013-01-02   93.139999\n",
       "2  2013-01-03   92.970001\n",
       "3  2013-01-04   93.120003\n",
       "4  2013-01-07   93.199997"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading Oil dataset\n",
    "oil = pd.read_sql_query(\"SELECT * FROM dbo.oil\", connection)\n",
    "\n",
    "# Saving the DataFrame to a CSV file\n",
    "oil.to_csv('data/oil.csv', index=False)\n",
    "\n",
    "oil.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>type</th>\n",
       "      <th>locale</th>\n",
       "      <th>locale_name</th>\n",
       "      <th>description</th>\n",
       "      <th>transferred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-03-02</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>Local</td>\n",
       "      <td>Manta</td>\n",
       "      <td>Fundacion de Manta</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-04-01</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Cotopaxi</td>\n",
       "      <td>Provincializacion de Cotopaxi</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-04-12</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>Local</td>\n",
       "      <td>Cuenca</td>\n",
       "      <td>Fundacion de Cuenca</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-04-14</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>Local</td>\n",
       "      <td>Libertad</td>\n",
       "      <td>Cantonizacion de Libertad</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-04-21</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>Local</td>\n",
       "      <td>Riobamba</td>\n",
       "      <td>Cantonizacion de Riobamba</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date     type    locale locale_name                    description  \\\n",
       "0  2012-03-02  Holiday     Local       Manta             Fundacion de Manta   \n",
       "1  2012-04-01  Holiday  Regional    Cotopaxi  Provincializacion de Cotopaxi   \n",
       "2  2012-04-12  Holiday     Local      Cuenca            Fundacion de Cuenca   \n",
       "3  2012-04-14  Holiday     Local    Libertad      Cantonizacion de Libertad   \n",
       "4  2012-04-21  Holiday     Local    Riobamba      Cantonizacion de Riobamba   \n",
       "\n",
       "   transferred  \n",
       "0        False  \n",
       "1        False  \n",
       "2        False  \n",
       "3        False  \n",
       "4        False  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading holidays_events dataset\n",
    "holidays_events = pd.read_sql_query(\n",
    "    \"SELECT * FROM dbo.holidays_events\", connection)\n",
    "\n",
    "# Saving the DataFrame to a CSV file\n",
    "holidays_events.to_csv('data/holidays_events.csv', index=False)\n",
    "\n",
    "holidays_events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>type</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Santo Domingo</td>\n",
       "      <td>Santo Domingo de los Tsachilas</td>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   store_nbr           city                           state type  cluster\n",
       "0          1          Quito                       Pichincha    D       13\n",
       "1          2          Quito                       Pichincha    D       13\n",
       "2          3          Quito                       Pichincha    D        8\n",
       "3          4          Quito                       Pichincha    D        9\n",
       "4          5  Santo Domingo  Santo Domingo de los Tsachilas    D        4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading stores dataset\n",
    "stores = pd.read_sql_query(\"SELECT * FROM dbo.stores\", connection)\n",
    "\n",
    "# Saving the DataFrame to a CSV file\n",
    "stores.to_csv('data/stores.csv', index=False)\n",
    "\n",
    "stores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        date  store_nbr      family  sales  onpromotion\n",
       "0   0  2013-01-01          1  AUTOMOTIVE    0.0            0\n",
       "1   1  2013-01-01          1   BABY CARE    0.0            0\n",
       "2   2  2013-01-01          1      BEAUTY    0.0            0\n",
       "3   3  2013-01-01          1   BEVERAGES    0.0            0\n",
       "4   4  2013-01-01          1       BOOKS    0.0            0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('Data/train.csv')\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000888</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3000889</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000890</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3000891</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000892</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id        date  store_nbr      family  onpromotion\n",
       "0  3000888  2017-08-16          1  AUTOMOTIVE            0\n",
       "1  3000889  2017-08-16          1   BABY CARE            0\n",
       "2  3000890  2017-08-16          1      BEAUTY            2\n",
       "3  3000891  2017-08-16          1   BEVERAGES           20\n",
       "4  3000892  2017-08-16          1       BOOKS            0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('Data/test.csv')\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>transactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>2111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>2</td>\n",
       "      <td>2358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>3</td>\n",
       "      <td>3487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>4</td>\n",
       "      <td>1922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  store_nbr  transactions\n",
       "0  2013-01-01         25           770\n",
       "1  2013-01-02          1          2111\n",
       "2  2013-01-02          2          2358\n",
       "3  2013-01-02          3          3487\n",
       "4  2013-01-02          4          1922"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions = pd.read_csv('Data/transactions.csv')\n",
    "\n",
    "transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000888</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3000889</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000890</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3000891</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000892</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  sales\n",
       "0  3000888    0.0\n",
       "1  3000889    0.0\n",
       "2  3000890    0.0\n",
       "3  3000891    0.0\n",
       "4  3000892    0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission = pd.read_csv('Data/sample_submission.csv')\n",
    "\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Cleaning and Preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Missing Values Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(id             0\n",
       " date           0\n",
       " store_nbr      0\n",
       " family         0\n",
       " sales          0\n",
       " onpromotion    0\n",
       " dtype: int64,\n",
       " id             0\n",
       " date           0\n",
       " store_nbr      0\n",
       " family         0\n",
       " onpromotion    0\n",
       " dtype: int64,\n",
       " date            0\n",
       " store_nbr       0\n",
       " transactions    0\n",
       " dtype: int64,\n",
       " store_nbr    0\n",
       " city         0\n",
       " state        0\n",
       " type         0\n",
       " cluster      0\n",
       " dtype: int64,\n",
       " date           0\n",
       " dcoilwtico    43\n",
       " dtype: int64,\n",
       " date           0\n",
       " type           0\n",
       " locale         0\n",
       " locale_name    0\n",
       " description    0\n",
       " transferred    0\n",
       " dtype: int64,\n",
       " id       0\n",
       " sales    0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for missing values in each dataset\n",
    "missing_values_train = train.isnull().sum()\n",
    "missing_values_test = test.isnull().sum()\n",
    "missing_values_transactions = transactions.isnull().sum()\n",
    "missing_values_stores = stores.isnull().sum()\n",
    "missing_values_oil = oil.isnull().sum()\n",
    "missing_values_holidays_events = holidays_events.isnull().sum()\n",
    "missing_values_sample_submission = sample_submission.isnull().sum()\n",
    "\n",
    "missing_values_train, missing_values_test, missing_values_transactions, missing_values_stores, missing_values_oil, missing_values_holidays_events, missing_values_sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date          0\n",
       "dcoilwtico    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filling missing values in the oil dataset using forward fill\n",
    "oil['dcoilwtico'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Verifying that there are no more missing values\n",
    "missing_values_oil = oil.isnull().sum()\n",
    "missing_values_oil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date          0\n",
       "dcoilwtico    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filling the remaining missing value using backward fill\n",
    "oil['dcoilwtico'].fillna(method='bfill', inplace=True)\n",
    "\n",
    "# Verifying that there are no more missing values\n",
    "missing_values_oil = oil.isnull().sum()\n",
    "missing_values_oil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Data Types Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting date columns to datetime format\n",
    "train['date'] = pd.to_datetime(train['date'])\n",
    "test['date'] = pd.to_datetime(test['date'])\n",
    "transactions['date'] = pd.to_datetime(transactions['date'])\n",
    "oil['date'] = pd.to_datetime(oil['date'])\n",
    "holidays_events['date'] = pd.to_datetime(holidays_events['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Merging Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge train dataset with transactions, stores, oil, and holidays_events\n",
    "train_merged = train.merge(transactions, on=['date', 'store_nbr'], how='left')\n",
    "train_merged = train_merged.merge(stores, on='store_nbr', how='left')\n",
    "train_merged = train_merged.merge(oil, on='date', how='left')\n",
    "train_merged = train_merged.merge(holidays_events, on='date', how='left')\n",
    "\n",
    "# Repeat the same for the test dataset\n",
    "test_merged = test.merge(transactions, on=['date', 'store_nbr'], how='left')\n",
    "test_merged = test_merged.merge(stores, on='store_nbr', how='left')\n",
    "test_merged = test_merged.merge(oil, on='date', how='left')\n",
    "test_merged = test_merged.merge(holidays_events, on='date', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Creating Date Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create additional features from the date\n",
    "train_merged['year'] = train_merged['date'].dt.year\n",
    "train_merged['month'] = train_merged['date'].dt.month\n",
    "train_merged['day'] = train_merged['date'].dt.day\n",
    "train_merged['dayofweek'] = train_merged['date'].dt.dayofweek\n",
    "\n",
    "test_merged['year'] = test_merged['date'].dt.year\n",
    "test_merged['month'] = test_merged['date'].dt.month\n",
    "test_merged['day'] = test_merged['date'].dt.day\n",
    "test_merged['dayofweek'] = test_merged['date'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Handling Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correctly rename columns before one-hot encoding\n",
    "train_merged.rename(columns={'type_x': 'store_type',\n",
    "                    'type_y': 'holiday_type'}, inplace=True)\n",
    "test_merged.rename(columns={'type_x': 'store_type',\n",
    "                   'type_y': 'holiday_type'}, inplace=True)\n",
    "\n",
    "# Convert categorical variables to numeric using one-hot encoding\n",
    "categorical_columns = ['family', 'city', 'state', 'store_type',\n",
    "                       'holiday_type', 'locale', 'locale_name', 'description', 'transferred']\n",
    "train_final = pd.get_dummies(\n",
    "    train_merged, columns=categorical_columns, drop_first=True)\n",
    "test_final = pd.get_dummies(\n",
    "    test_merged, columns=categorical_columns, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exploratory Data Analysis (EDA)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sales trends over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate sales by date to see the overall trend\n",
    "sales_trend = train_merged.groupby('date')['sales'].sum().reset_index()\n",
    "\n",
    "# Plot the overall sales trend\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(sales_trend['date'], sales_trend['sales'], label='Sales')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Total Sales')\n",
    "plt.title('Overall Sales Trend Over Time')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seasonality and Monthly Sales Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate sales by month and year\n",
    "monthly_sales = train_merged.groupby(['year', 'month'])[\n",
    "    'sales'].sum().unstack()\n",
    "\n",
    "# Plot monthly sales patterns\n",
    "plt.figure(figsize=(14, 7))\n",
    "monthly_sales.plot(kind='bar', stacked=True,\n",
    "                   colormap='viridis', figsize=(14, 7))\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Total Sales')\n",
    "plt.title('Monthly Sales Patterns Over Years')\n",
    "plt.legend(title='Month', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sales Distribution Across Stores and Product Families"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate sales by store and product family\n",
    "store_sales = train_merged.groupby('store_nbr')['sales'].sum(\n",
    ").sort_values(ascending=False).reset_index()\n",
    "family_sales = train_merged.groupby(\n",
    "    'family')['sales'].sum().sort_values(ascending=False).reset_index()\n",
    "\n",
    "# Plot sales distribution across stores\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.bar(store_sales['store_nbr'], store_sales['sales'])\n",
    "plt.xlabel('Store Number')\n",
    "plt.ylabel('Total Sales')\n",
    "plt.title('Sales Distribution Across Stores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sales distribution across product families\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.barh(family_sales['family'], family_sales['sales'])\n",
    "plt.xlabel('Total Sales')\n",
    "plt.ylabel('Product Family')\n",
    "plt.title('Sales Distribution Across Product Families')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impact of Promotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate sales by promotion status\n",
    "promotion_sales = train_merged.groupby(\n",
    "    'onpromotion')['sales'].sum().reset_index()\n",
    "\n",
    "# Plot impact of promotions on sales\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(promotion_sales['onpromotion'],\n",
    "        promotion_sales['sales'], color=['blue', 'orange'])\n",
    "plt.xlabel('On Promotion')\n",
    "plt.ylabel('Total Sales')\n",
    "plt.title('Impact of Promotions on Sales')\n",
    "plt.xticks([0, 1], ['No', 'Yes'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impact of Oil Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sales versus oil prices\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(train_merged['date'], train_merged['sales'], label='Sales')\n",
    "plt.plot(train_merged['date'], train_merged['dcoilwtico'],\n",
    "         label='Oil Price', color='orange')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Sales vs Oil Prices')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impact of Holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate sales by holiday status\n",
    "holiday_sales = train_merged.groupby(\n",
    "    'holiday_type')['sales'].sum().reset_index()\n",
    "\n",
    "# Plot impact of holidays on sales\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.bar(holiday_sales['holiday_type'], holiday_sales['sales'], color='green')\n",
    "plt.xlabel('Holiday Type')\n",
    "plt.ylabel('Total Sales')\n",
    "plt.title('Impact of Holidays on Sales')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Hypothesis Testing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Null Hypothesis (H0a): Promotions do not have a significant impact on sales.  \n",
    "\n",
    "Alternative Hypothesis (H1a): Promotions have a significant impact on sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Separate sales data for promoted and non-promoted products\n",
    "promoted_sales = train_merged[train_merged['onpromotion'] > 0]['sales']\n",
    "non_promoted_sales = train_merged[train_merged['onpromotion'] == 0]['sales']\n",
    "\n",
    "# Perform t-test\n",
    "t_stat, p_value = ttest_ind(promoted_sales, non_promoted_sales)\n",
    "\n",
    "t_stat, p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Null Hypothesis (H0b): Oil prices do not significantly impact sales.  \n",
    "\n",
    "Alternative Hypothesis (H1b): Oil prices significantly impact sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in the oil prices\n",
    "train_merged['dcoilwtico'].fillna(method='ffill', inplace=True)\n",
    "train_merged['dcoilwtico'].fillna(method='bfill', inplace=True)\n",
    "\n",
    "# Verify there are no more missing values\n",
    "train_merged['dcoilwtico'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Extract sales and oil prices\n",
    "sales = train_merged['sales']\n",
    "oil_prices = train_merged['dcoilwtico']\n",
    "\n",
    "# Perform Pearson correlation\n",
    "correlation, p_value = pearsonr(sales, oil_prices)\n",
    "\n",
    "correlation, p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Analytical Questions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merged['date'].min(), train_merged['date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting dates which are not in the train dataset\n",
    "missing_dates = pd.date_range(\n",
    "    start='2013-01-01', end='2017-08-15').difference(train_merged.date)\n",
    "\n",
    "# print(pd.date_range(start= '2013-01-01', end='2017-08-15').difference(train.index))\n",
    "missing_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating variables as arguments for the product() method\n",
    "uniques_stores = train_merged.store_nbr.unique()\n",
    "unique_family = train_merged.family.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will replace the missing dates by pairing it with all the unique stores and families\n",
    "replace_dates = list(product(missing_dates, uniques_stores,unique_family ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dataframe for the replaced dates\n",
    "replace_dates_df = pd.DataFrame(\n",
    "    replace_dates, columns=['date', 'store_nbr', 'family'])\n",
    "replace_dates_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding replaced dates to our train data\n",
    "train_merged = pd.concat([train_merged, replace_dates_df], ignore_index=True)\n",
    "train_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_dates = pd.date_range(\n",
    "    start='2013-01-01', end='2017-08-15').difference(train_merged.date)\n",
    "missing_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Which dates have the lowest and highest sales for each year(excluding days the store was closed)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify dates when stores were closed (i.e., zero transactions)\n",
    "closed_dates = transactions[transactions['transactions'] == 0]['date'].unique()\n",
    "\n",
    "# Filter out closed dates from the sales data\n",
    "sales_data = train_merged[~train_merged['date'].isin(closed_dates)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year from the date\n",
    "sales_data['year'] = sales_data['date'].dt.year\n",
    "\n",
    "# Group by year and date, then sum the sales\n",
    "yearly_sales = sales_data.groupby(['year', 'date'])[\n",
    "    'sales'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Did the earthquake impact sales?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:A magnitude 7.8 earthquake struck Ecuador on April 16, 2016. People rallied in relief efforts donating water and other first need products which greatly affected supermarket sales for several weeks after the earthquake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pre-earthquake and post-earthquake periods\n",
    "pre_earthquake = train_merged[train_merged['date'] < '2016-04-16']\n",
    "post_earthquake = train_merged[train_merged['date'] >= '2016-04-16']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate sales data for pre-earthquake and post-earthquake periods\n",
    "pre_earthquake_sales = pre_earthquake.groupby(\n",
    "    'date')['sales'].sum().reset_index()\n",
    "post_earthquake_sales = post_earthquake.groupby(\n",
    "    'date')['sales'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sales over time, highlighting the earthquake date\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(pre_earthquake_sales['date'],\n",
    "         pre_earthquake_sales['sales'], label='Pre-Earthquake')\n",
    "plt.plot(post_earthquake_sales['date'], post_earthquake_sales['sales'],\n",
    "         label='Post-Earthquake', color='orange')\n",
    "plt.axvline(pd.to_datetime('2016-04-16'), color='red',\n",
    "            linestyle='--', label='Earthquake')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Total Sales')\n",
    "plt.title('Sales Before and After the Earthquake on April 16, 2016')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform t-test to compare sales before and after the earthquake\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Combine sales data for t-test\n",
    "pre_earthquake_sales_total = pre_earthquake_sales['sales']\n",
    "post_earthquake_sales_total = post_earthquake_sales['sales']\n",
    "\n",
    "# Perform t-test\n",
    "t_stat_earthquake, p_value_earthquake = ttest_ind(\n",
    "    pre_earthquake_sales_total, post_earthquake_sales_total)\n",
    "\n",
    "t_stat_earthquake, p_value_earthquake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Are certain groups of stores selling more products? (Cluster, city, state, type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate sales by cluster\n",
    "cluster_sales = train_merged.groupby('cluster')['sales'].sum().reset_index()\n",
    "\n",
    "# Aggregate sales by city\n",
    "city_sales = train_merged.groupby('city')['sales'].sum().reset_index()\n",
    "\n",
    "# Aggregate sales by state\n",
    "state_sales = train_merged.groupby('state')['sales'].sum().reset_index()\n",
    "\n",
    "# Aggregate sales by store type\n",
    "store_type_sales = train_merged.groupby('store_type')['sales'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sales by Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 7))\n",
    "plt.bar(cluster_sales['cluster'], cluster_sales['sales'])\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Total Sales')\n",
    "plt.title('Total Sales by Cluster')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sales by City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 7))\n",
    "plt.bar(city_sales['city'], city_sales['sales'])\n",
    "plt.xlabel('City')\n",
    "plt.ylabel('Total Sales')\n",
    "plt.title('Total Sales by City')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sales by state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 7))\n",
    "plt.bar(state_sales['state'], state_sales['sales'])\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Total Sales')\n",
    "plt.title('Total Sales by State')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sales by Store Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 7))\n",
    "plt.bar(store_type_sales['store_type'], store_type_sales['sales'])\n",
    "plt.xlabel('Store Type')\n",
    "plt.ylabel('Total Sales')\n",
    "plt.title('Total Sales by Store Type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Are sales affected by promotions, oil prices and holidays?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impact of Promotions on Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Create box plot for promotions\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.boxplot(x='onpromotion', y='sales', data=train_merged)\n",
    "plt.xlabel('On Promotion')\n",
    "plt.ylabel('Sales')\n",
    "plt.title('Impact of Promotions on Sales')\n",
    "plt.xticks([0, 1], ['No', 'Yes'])\n",
    "plt.show()\n",
    "\n",
    "# Perform t-test for promotions\n",
    "promoted_sales = train_merged[train_merged['onpromotion'] > 0]['sales']\n",
    "non_promoted_sales = train_merged[train_merged['onpromotion'] == 0]['sales']\n",
    "t_stat_promotions, p_value_promotions = ttest_ind(\n",
    "    promoted_sales, non_promoted_sales)\n",
    "\n",
    "t_stat_promotions, p_value_promotions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impact of Oil Prices on Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Create scatter plot for oil prices\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.scatter(train_merged['dcoilwtico'], train_merged['sales'], alpha=0.3)\n",
    "plt.xlabel('Oil Price')\n",
    "plt.ylabel('Sales')\n",
    "plt.title('Impact of Oil Prices on Sales')\n",
    "plt.show()\n",
    "\n",
    "# Compute Pearson correlation for oil prices\n",
    "correlation_oil, p_value_oil = pearsonr(\n",
    "    train_merged['sales'], train_merged['dcoilwtico'])\n",
    "\n",
    "correlation_oil, p_value_oil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impact of Holidays on Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create box plot for holidays\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.boxplot(x='holiday_type', y='sales', data=train_merged)\n",
    "plt.xlabel('Holiday Type')\n",
    "plt.ylabel('Sales')\n",
    "plt.title('Impact of Holidays on Sales')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Perform t-test for holidays\n",
    "holiday_sales = train_merged[train_merged['holiday_type'] != 'None']['sales']\n",
    "non_holiday_sales = train_merged[train_merged['holiday_type'] == 'None']['sales']\n",
    "t_stat_holidays, p_value_holidays = ttest_ind(holiday_sales, non_holiday_sales)\n",
    "\n",
    "t_stat_holidays, p_value_holidays"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
